# 2018中国“法研杯”法律智能挑战赛 CAIL2018

## 0 大赛简介

法律智能旨在赋予机器阅读理解法律文本与定量分析案例的能力，完成罪名预测、法律条款推荐、刑期预测等具有实际应用需求的任务，有望辅助法官、律师等人士更加高效地进行法律判决。近年来，以深度学习和自然语言处理为代表的人工智能技术取得巨大突破，也开始在法律智能领域崭露头角，受到学术界和产业界的广泛关注。 

## 1 挑战赛详情

### 1.1 挑战赛任务
- 任务一  罪名预测：根据刑事法律文书中的案情描述和事实部分，预测被告人被判的罪名；

- 任务二  法条推荐：根据刑事法律文书中的案情描述和事实部分，预测本案涉及的相关法条；

- 任务三  刑期预测：根据刑事法律文书中的案情描述和事实部分，预测被告人的刑期长短。

### 1.2 数据介绍
本次挑战赛所使用的数据集是来自“中国裁判文书网”公开的刑事法律文书，其中每份数据由法律文书中的案情描述和事实部分组成，同时也包括每个案件所涉及的法条、被告人被判的罪名和刑期长短等要素。

数据集共包括268万刑法法律文书，共涉及183条罪名，202条法条，刑期长短包括0-25年、无期、死刑。

- CAIL2018-Small包括19.6万份文书样例，直接在该网站发布，包括15万训练集，1.6万验证集和3万测试集。这部分数据可以自由下载，供前期训练和测试。

- CAIL2018-Large数据集，包括150万文书样例。

- 最后，剩余90万份文书将作为第一阶段的测试数据CAIL2018-Large-test。


### 1.3 评价方法
本次挑战赛使用的数据集均为来自中国裁判文书网上的刑事法律文书，标准答案是案件的判决结果。下面将对三项任务的评价方法分别进行说明：

- 任务一、任务二的评价方式：

    任务一（罪名预测）、任务二（法条推荐）两项任务将采用分类任务中的微平均F1值（Micro-F1-measure）和宏平均F1值（Macro-F1-measure）作为评价指标。

- 任务三评价方式：

    任务三（刑期预测）将根据预测出的刑期与案件标准刑期之间的差值距离作为评价指标。

- 三项任务总分的计算方式：

    每个任务的满分均为100，则总分为：score_all = score_1 + scroe_2 + score_3
    
### 1.4 基线系统：

竞赛组织方将提供三个开源的针对不同任务的基线系统（LibSVM、RNN、CNN等）。


## 2 赛程安排

### 2.1 第一阶段（2018.05.15-2018.07.14） :  

开启报名，发放CAIL2018-Small数据，用于编写模型进行训练和测试。每周限提交3次，开放排行榜；

第一阶段开始3周之后（计划6月5日，可能根据参赛队伍情况调整，具体时间请关注官方网站公告栏），根据参赛者提交结果情况。对于高于预设基准算法成绩的队伍，我们将通过邮寄U盘（或网络下载）定向发布CAIL2018-Large数据集，包括新增的170万份样例。发放结束后将于1周之内（计划6月12日，可能根据参赛队伍情况调整，具体时间请关注官方网站公告栏）利用全部测试数据CAIL2018-Large-test进行重新评测，刷新排行榜。第一阶段的最终成绩以各参赛队伍7月14日之前提交的最终比赛模型（或最后提交的模型）在全部测试数据CAIL2018-Large-test上的成绩为准。

### 2.2 第二阶段（2018.07.14-2018.08.14） :  

封闭评测，第一阶段结束时，所有参赛者提交最终比赛模型（或以最后提交的模型为准）。同时，主办方将收集中国裁判文书网在随后一个月内每天新增的裁判文书数据作为新的测试集，对各参赛者的模型进行封闭评测，得到最终成绩。

挑战赛的最终成绩计算方式：最终成绩 = 第一阶段的成绩 * 0.3 + 第二阶段的成绩 * 0.7

### 2.3 技术交流和颁奖活动（2018.09）

## 团队成员

冯柏淋 @FengBli

陈子彧 @mcorange1997
